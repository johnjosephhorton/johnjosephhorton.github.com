<!doctype html>
<!-- https://github.com/paulirish/html5-boilerplate/blob/master/index.html -->
<!-- paulirish.com/2008/conditional-stylesheets-vs-css-hacks-answer-neither/ -->
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
    <meta charset="">

  <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame
       Remove this if you use the .htaccess -->
  <meta http-equiv="X-UA-Compatible" content="">

  <!-- encoding must be specified within the first 512 bytes
        www.whatwg.org/specs/web-apps/current-work/multipage/semantics.html#charset -->

  <!-- meta element for compatibility mode needs to be before
        all elements except title & meta
        msdn.microsoft.com/en-us/library/cc288325(VS.85).aspx -->
  <!-- Chrome Frame is only invoked if meta element for
        compatibility mode is within the first 1K bytes
        code.google.com/p/chromium/issues/detail?id=23003 -->

  <title>All public government data should be easily machine readable</title>
  <meta name="description" content="John J. Horton
">
  <meta name="author" content="Lakshmi Vyasarajan">

  <!--  Mobile viewport optimized: j.mp/bplateviewport -->
  <meta name="viewport" content="">

    <!-- Place favicon.ico & apple-touch-icon.png
        in the root of your domain and delete these references -->
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
    <link rel="stylesheet" href="/media/css/site.css">
  <link rel="stylesheet" href="/media/css/syntax.css">
  <link rel="stylesheet" href="/media/css/bootstrap.min.css">
  <link rel="stylesheet" href="/media/css/extra.css">
  
    <!-- All JavaScript at the bottom, except for Modernizr which
        enables HTML5 elements & feature detects -->
    <script src="/media/js/libs/modernizr-1.7.min.js"></script>
    <script src="/media/js/bootstrap.min.js"></script>
    </head>
<body id="all-public-government-data-should-be">
    <div id="container">
            <div id="main" role="main">
          <header class="banner clearfix">
          <h1>John J. Horton </h1>
            <h3>

</h3>                              <nav class=main_nav>
<div class='navbar'>
<div class='navbar-inner'>
<div class='container'>
    <ul class='nav nav-pills'>
                <li class=" about">
            <a title="About"
                class=" about"
                href="/index.html">
                About
            </a>
        </li>        <li class=" active blog">
            <a title="Blog"
                class=" active blog"
                href="/blog">
                Online Labor Blog
            </a>
        </li>        <li class=" papers">
            <a title="Papers"
                class=" papers"
                href="/papers">
                Papers
            </a>
        </li>        <li class=" portfolio">
            <a title="Portfolio"
                class=" portfolio"
                href="/portfolio">
                CV
            </a>
        </li>    </ul>
</div>
</div>
</div>
</nav>
                    </header>
	  <hr>
          <section class="content">
          <div class='float_right'>
<a href="https://twitter.com/johnjhorton" class="twitter-follow-button" data-show-count="false">Follow @johnjhorton</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</div>
<article class="post">
<nav class="post_nav">
<a class="backlink" href="/blog">Back to list</a>
<a class="prev"
    title="Some light data munging with R, with an application to ranking NFL Teams"
        href="/blog/some-light-data-munging-with-r-with.html">
    Previous
</a>

<a class="next"
    title="We can always get jobs working at the local robot factory"
        href="/blog/we-can-always-get-jobs-working-at-local.html">
    Next
</a>

<br>
<div id="twitter_share">
<a href="http://twitter.com/share"
    class="twitter-share-button"
    data-count="vertical"
    data-via="ringce">Tweet</a>
    <script type="text/javascript"
        src="http://platform.twitter.com/widgets.js"></script>
</div>
<div id="facebook_like">
<iframe src="http://www.facebook.com/plugins/like.php?href&amp;layout=box_count&amp;show_faces=false&amp;width=450&amp;action=like&amp;font=arial&amp;colorscheme=light&amp;height=65"
            scrolling="no"
            frameborder="0"
            style="border:none; overflow:hidden; width:450px; height:65px;"
            allowTransparency="true"></iframe>
</div>
</nav>
<h1 class="title">
    <a href="/blog/all-public-government-data-should-be.html">
        All public government data should be easily machine readable
    </a>
</h1>
<time datetime="2011-10-02">
    Posted: Sun, 02 Oct 2011
</time>

<ul class="tags clear">
<li>
    <a class="small" href="/blog/tags/Statistics.html">
        Statistics
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/Python.html">
        Python
    </a>
</li>
<li>
    <a class="small" href="/blog/tags/Programming.html">
        Programming
    </a>
</li>
</ul>
<p>The Bureau of Labor Statistics (<span class="caps">BLS</span>) has an annual budget of over $640 million (<span class="caps">FY</span> 2011), 
a budget  they use to create and then distribute detailed labor market data and analysis to policy makers, 
researchers, journalists and the general public. I can&#8217;t speak to the &#8220;creation&#8221; part of their mission, 
but on the &#8220;distribution&#8221; part, the are failing&#8211;organizations with tiny fractions of their resources do a far better job.
It&#8217;s not the case that government <span class="caps">IT</span> is invariably bad&#8211;the Federal Reserve Bank of St. Louis has an amazing 
interface (<span class="caps">FRED</span>) and <a href="http://api.stlouisfed.org/docs/fred/"><span class="caps">API</span></a> for working with their data. 
Unfortunately, not all government statistics are available here, especially some of the more interesting <span class="caps">BLS</span> series.<br />
</p>
<p>The essential problem with <span class="caps">BLS</span> is that all of their work products&#8211;reports, tables etc.&#8211;are 
designed to be printed out, not accessed electronically. Many <span class="caps">BLS</span> tables are embedded in PDFs, 
which makes the data they contain essentially impossible to extract; non-<span class="caps">PDF</span>, text-based tables, 
which are better, are difficult to parse electronically: structure is conveyed by tabs and white space, 
column headings are split over multiple lines with no separators; heading lengths vary etc.<br />
</p>
<p>Why does it matter? For one, when users can access data electronically, via an <span class="caps">API</span>, 
they can combine it with other sources, look for patterns, test hypotheses, find bugs / 
measurement errors, create visualization and do all sorts of other things that make the data more useful.<br />
</p>
<hr />
<p><span class="caps">BLS</span> does offer a <span class="caps">GUI</span> tool for downloading data, but it&#8217;s kludgy, requires a Java Applet, 
requires series to be hand-selected and then returns an Excel(!) spreadsheet w/ extraneous headers 
and formatting. Furthermore, it&#8217;s not clear what series and what transformations are needed from <span class="caps">GUI</span>-data to 
make the more refined, aggregated tables.<br />
</p>
<hr />
<p>To illustrate how hard it is to get the data out, I wrote a python script to extract the results this table 
(which shows the expected and estimated changes in employment for a number of industries). 
What I wanted to do was make this, which I think is far easier to understand than the table alone:<br />
</p>
<p><img alt="Image" src="https://img.skitch.com/20111002-t9f89cdsp7cnewqcmf63wd1s3y.jpg" /><br />
</p>
<p>To actually create this figure, I needed to get data into in R by way of a <span class="caps">CSV</span> file.  The code required to get table data into a useful <span class="caps">CSV</span> file, while not rocket science, isn&#8217;t trivial&#8211;there&#8217;s lots of one-off/hacky things to work around the limitations of the table. Getting the nested structure of the industries e.g., (&#8220;Durable Goods&#8221; is a subset of &#8220;Manufacturing&#8221; and &#8220;Durable Goods&#8221; has 4 sub-classifications) required recursion (see the &#8220;bread_crumb&#8221; function). <span class="caps">FWIW</span>, here&#8217;s the code:<br />
</p>
<pre><code>import urllib2
import csv

FIRST_LINE = 11
LAST_LINE = 38

def get_level(l):
    for i, char in enumerate(l):
        if char != " ":
            break
    return i

def clean_line(l):
    l = l.replace("\r","")
    l = l.replace("\n","")
    l = l.split(" ")
    return [y.strip() for y in l if y!=""]

f = urllib2.urlopen("ftp://ftp.bls.gov/pub/suppl/empsit.tab1.txt")
lines = [line for line in f][FIRST_LINE:LAST_LINE]
levels = map(get_level, lines)
data_rows = map(clean_line, lines)
headings = [y[0] for y in data_rows]

d_order = dict(zip(headings, range(len(headings))))
d_level = dict(zip(headings, levels))

def one_up(heading):
    candidates = headings[:d_order[heading]]
    heading_level = d_level[heading]
    candidates.reverse()
    for c in candidates:
        if d_level[c] &lt; heading_level:
            return c
    else:
        return None

def crumb_trail(heading):
    if one_up(heading) is None:
        return [heading]
    else:
        return crumb_trail(one_up(heading)) + [heading]

crumb_trails = map(crumb_trail, headings)
max_depth = max(map(len, crumb_trails))

g = open("bls.csv", "w")
header = ["level_%s" % i for i in range(max_depth)] + [
    "depth", "level", "normal_seasonal_movement", "estimated_over_month_change",
 "sa_adjusted_over_month_change"]

hier = dict(zip(set(levels), range(len(set(levels)))))
def get_hier(heading): return hier[d_level[heading]]

out = csv.writer(g)
out.writerow(header)
for trail, data_row in zip(crumb_trails, data_rows):
    industry = [None for i in range(max_depth)]
    indices = map(get_hier, trail)
    depth = max(indices)
    for name, i in zip(trail, indices):
        industry[i] = name
    out.writerow(industry + [depth] + data_row[:3])
g.close()
</code></pre>
<p>Most of the code is dealing with the problems shows in this sketch:<br />
</p>
<p><img alt="Image" src="https://img.skitch.com/20111002-r81md92f22sqcfp15m6kdisai9.jpg" /><br />
</p>
<p>My suggestion: <span class="caps">BLS</span> should borrow someone from <span class="caps">FRED</span> and help them create a proper <span class="caps">API</span>.<br />
</p></article>
 <center><a href="/blog/atom.xml"><< Subscribe via RSS Feed >></a></center>          </section>
      </div>
      </div> <!--! end of #container -->
  <footer>
    
  </footer>
      <!-- Javascript at the bottom for fast page loading -->
    <!-- Grab Google CDN's jQuery, with a protocol relative URL; fall back to local if necessary -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.js"></script>
  <script>window.jQuery || document.write('<script src="js/libs/jquery-1.5.1.min.js">\x3C/script>')</script>
  
    

  <!--[if lt IE 7 ]>
    <script src="js/libs/dd_belatedpng.js"></script>
    <script>DD_belatedPNG.fix('img, .png_bg'); // Fix any <img> or .png_bg bg-images. Also, please read goo.gl/mZiyb </script>
  <![endif]-->

      
  </body>
</html>